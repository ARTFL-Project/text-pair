########################
## CONFIGURATION FILE ##
########################

[TEI_PARSING]
##########################################################################
## If TEI parsing was not done by an external process (eg. PhiloLogic), ##
## you can parse your source and target files using the provided xml    ##
## parser in utils/                                                     ##
##########################################################################

# Defines whether to parse source files
parse_source_files = yes

# Defines whether to parse target files
parse_target_files = false


[PREPROCESSING]
# Defines what object level to divide each text into
source_text_object_level = doc
target_text_object_level = doc

# Defines how many tokens constitute a ngram
ngram = 3

# Defines how many gap inside a ngram
gap = 2

# Setting skipgram to True means only the first and last token are kept in ngrams
# So a trigram will keep tokens 1 and 3, a quadgram will keep tokens 1 and 4 and so on...
skipgram = False

# Language: set the language for various normalization tasks
# such as stemming, lemmatizing, word mapping...etc
language = french

# Stem words using the Porter Stemmer
stemmer = yes

# Lemmatizer: path to lemmatizer file where each line contains the inflected form and
# the corresponding lemma separated by a tab
lemmatizer =

# Lowercase words
lowercase = yes

# Remove numbers
numbers = yes

# Stopwords: path to stopword list
stopwords = /local/spinel/ownCloud/Python/StopWords/french.txt

# Only posssible with a Philologic4 index
# Useful to break up a single document into smaller text units
text_object_level = doc


[MATCHING]
########################
## PROCESSING OPTIONS ##
########################

# Sort files prior to matching. This may be important when wanting to avoid
# comparing a source file with a target file that occurs later in time
sort_by = year

# Turn on batch mode for source files and/or target_files and define the size of each batch as
# a dividing number
source_batch = 1
target_batch = 1

# Size of left and right context in bytes
context_size = 300

# Output path of results. If nothing set, defaults to current directory
output_path =

# Location of ngram index used for debugging. Should be the source or target index, not matter which since it'll be used for common ngrams
ngram_index =

#########################
## MATCHING PARAMETERS ##
#########################

# Size of ngram window to be initially evaluated in the sequence aligner
matching_window_size = 20

# Minimum number of shared ngrams between docs to start a comparison
minimum_matching_ngrams_in_docs = 4

# Percentage of shared ngrams between 2 docs to consider the target as a duplicate of source
duplicate_threshold = 50

# Minimum number of matching ngrams in ngram window
minimum_matching_ngrams_in_window = 4

# Maximum gap authorized between matching ngrams
max_gap = 10

# Minimum number of matching ngrams to constitute a match
minimum_matching_ngrams  = 4

###################################
## PASSAGE MERGING AND EXTENDING ##
###################################

# If set to true, this will disable two-way matching: not recommended
one_way_matching = false

# Merge passages within n number of byte: number defined by passage length and the passage_distance_multiplier option.
merge_passages_on_byte_distance = true

# Combine passage which are within (multiplier * length of previous passage) bytes. Needs merge_passages_on_byte_distance set to true
passage_distance_multiplier = 0.5

# Merge passages within n number of ngrams: the value used is the matching_window_size defaulting to 20
merge_passages_on_ngram_distance = true

#################################
## BANALITY DETECTION SETTINGS ##
#################################

# Pass a list of most common ngrams for source and/or target files to help with the detection
# of banalities
source_common_ngrams =
target_common_ngrams =

# Define the top n most common ngrams from source and target common ngrams
most_common_ngram_threshold = 1000

# The top common_ngrams_in_docs between two docs: used to define common, or banal ngrams.
banal_ngrams = 25

# Defines the maximum amount of common ngrams between two docs: this is effectively a banality measure.
# Ex: If we want to dismiss matches where more than 75% of matching ngrams are among the top n common ngrams between both docs
# we set the common_ngrams_limit to 75
common_ngrams_limit = 75
